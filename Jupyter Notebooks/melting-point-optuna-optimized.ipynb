{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785c6679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:34:57.815304Z",
     "iopub.status.busy": "2025-11-21T16:34:57.815070Z",
     "iopub.status.idle": "2025-11-21T18:41:08.967439Z",
     "shell.execute_reply": "2025-11-21T18:41:08.966781Z"
    },
    "papermill": {
     "duration": 7571.157014,
     "end_time": "2025-11-21T18:41:08.969338",
     "exception": false,
     "start_time": "2025-11-21T16:34:57.812324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2025.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rdkit) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rdkit) (9.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (1.17.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: tqdm in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: tomli in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from colorlog->optuna) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\linus\\appdata\\roaming\\python\\python310\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (6.5.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (2.13.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\linus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FC1=C(F)C(F)(F)C1(F)F</td>\n",
       "      <td>213.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1ccc2c(c1)ccc3Nc4ccccc4c23</td>\n",
       "      <td>407.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCN1C(C)=Nc2ccccc12</td>\n",
       "      <td>324.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC#CC(=O)O</td>\n",
       "      <td>351.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCC(S)C</td>\n",
       "      <td>126.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>ClCCBr</td>\n",
       "      <td>256.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>N#CC(Cl)(Cl)Cl</td>\n",
       "      <td>231.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>Cc1ccc2c(C)cccc2c1</td>\n",
       "      <td>256.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>CCC(=O)c1ccc2ccccc2c1</td>\n",
       "      <td>333.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>Brc1ccc(cc1)N(C)C</td>\n",
       "      <td>328.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2662 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SMILES      Tm\n",
       "0           FC1=C(F)C(F)(F)C1(F)F  213.15\n",
       "1     c1ccc2c(c1)ccc3Nc4ccccc4c23  407.15\n",
       "2             CCN1C(C)=Nc2ccccc12  324.15\n",
       "3                      CC#CC(=O)O  351.15\n",
       "4                       CCCCC(S)C  126.15\n",
       "...                           ...     ...\n",
       "2657                       ClCCBr  256.45\n",
       "2658               N#CC(Cl)(Cl)Cl  231.15\n",
       "2659           Cc1ccc2c(C)cccc2c1  256.25\n",
       "2660        CCC(=O)c1ccc2ccccc2c1  333.15\n",
       "2661            Brc1ccc(cc1)N(C)C  328.15\n",
       "\n",
       "[2662 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1022</td>\n",
       "      <td>CCOC(=O)c1ccc(O)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1146</td>\n",
       "      <td>CCCCCCc1ccc(O)cc1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>ClCBr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2279</td>\n",
       "      <td>C=CCCCCCCCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1342</td>\n",
       "      <td>Fc1ccc(cc1)C(F)(F)F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2663</td>\n",
       "      <td>CCCCCCCCC(=O)CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>624</td>\n",
       "      <td>COc1ccc(COC(=O)C)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2655</td>\n",
       "      <td>C#CCCC(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2089</td>\n",
       "      <td>BrCC(Br)C(Br)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1065</td>\n",
       "      <td>OCCCc1ccccc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                SMILES\n",
       "0    1022   CCOC(=O)c1ccc(O)cc1\n",
       "1    1146    CCCCCCc1ccc(O)cc1O\n",
       "2      79                 ClCBr\n",
       "3    2279           C=CCCCCCCCC\n",
       "4    1342   Fc1ccc(cc1)C(F)(F)F\n",
       "..    ...                   ...\n",
       "661  2663       CCCCCCCCC(=O)CC\n",
       "662   624  COc1ccc(COC(=O)C)cc1\n",
       "663  2655            C#CCCC(C)C\n",
       "664  2089        BrCC(Br)C(Br)C\n",
       "665  1065          OCCCc1ccccc1\n",
       "\n",
       "[666 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'There are 5237 Duplicated data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Drop Duplicated data!\n",
      "There Are 217 Descriptor Features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 135\u001b[0m\n\u001b[0;32m    130\u001b[0m     df_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat((df, df_descriptor), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_result\n\u001b[1;32m--> 135\u001b[0m merge_df \u001b[38;5;241m=\u001b[39m \u001b[43mextract_all_descriptors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSMILES\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m test_df  \u001b[38;5;241m=\u001b[39m extract_all_descriptors(test_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMILES\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# DROP NULL/NONE VALUE AFTER FEATURE ENGINEERING\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [6], line 124\u001b[0m, in \u001b[0;36mextract_all_descriptors\u001b[1;34m(df, SMILES)\u001b[0m\n\u001b[0;32m    121\u001b[0m         row \u001b[38;5;241m=\u001b[39m {name : \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name, func \u001b[38;5;129;01min\u001b[39;00m descriptor_list}\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;66;03m# CREATE DESCRIPTORS FEATURES\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m         row \u001b[38;5;241m=\u001b[39m {name: func(mol) \u001b[38;5;28;01mfor\u001b[39;00m name, func \u001b[38;5;129;01min\u001b[39;00m descriptor_list}\n\u001b[0;32m    126\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# MERGE DATA WITH EXTRACTED FEATURES\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [6], line 124\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    121\u001b[0m         row \u001b[38;5;241m=\u001b[39m {name : \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name, func \u001b[38;5;129;01min\u001b[39;00m descriptor_list}\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;66;03m# CREATE DESCRIPTORS FEATURES\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m         row \u001b[38;5;241m=\u001b[39m {name: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name, func \u001b[38;5;129;01min\u001b[39;00m descriptor_list}\n\u001b[0;32m    126\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# MERGE DATA WITH EXTRACTED FEATURES\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\linus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rdkit\\Chem\\GraphDescriptors.py:130\u001b[0m, in \u001b[0;36mIpc\u001b[1;34m(mol, avg, dMat, forceDMat)\u001b[0m\n\u001b[0;32m    127\u001b[0m       mol\u001b[38;5;241m.\u001b[39m_adjMat \u001b[38;5;241m=\u001b[39m dMat\n\u001b[0;32m    129\u001b[0m adjMat \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mequal(dMat, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 130\u001b[0m cPoly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[43mGraphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCharacteristicPolynomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjMat\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m avg:\n\u001b[0;32m    132\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m entropy\u001b[38;5;241m.\u001b[39mInfoEntropy(cPoly)\n",
      "File \u001b[1;32mc:\\Users\\linus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rdkit\\Chem\\Graphs.py:48\u001b[0m, in \u001b[0;36mCharacteristicPolynomial\u001b[1;34m(mol, mat)\u001b[0m\n\u001b[0;32m     46\u001b[0m   res[n] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m n \u001b[38;5;241m*\u001b[39m numpy\u001b[38;5;241m.\u001b[39mtrace(An)\n\u001b[0;32m     47\u001b[0m   Bn \u001b[38;5;241m=\u001b[39m An \u001b[38;5;241m-\u001b[39m res[n] \u001b[38;5;241m*\u001b[39m I\n\u001b[1;32m---> 48\u001b[0m   An \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m res[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%capture -> decommend if you dont want to see outputs\n",
    "%pip install rdkit\n",
    "%pip install optuna\n",
    "%pip install plotly\n",
    "%pip install xgboost\n",
    "%pip install openpyxl\n",
    "%pip install seaborn\n",
    "# ==========================================================================================\n",
    "# =================================== IMPORTS AND SETUP ====================================\n",
    "# ==========================================================================================\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Crippen, rdMolDescriptors, MACCSkeys, RDKFingerprint, rdFingerprintGenerator\n",
    "from rdkit.Chem.AtomPairs import Pairs, Torsions\n",
    "\n",
    "# DISABLE WARNING FROM rdkit\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "try:\n",
    "    from rdkit.Avalon import pyAvalonTools\n",
    "    avalon_available = True\n",
    "except ImportError:\n",
    "    avalon_available = False\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe_connected\"\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import xgboost\n",
    "\n",
    "# ==========================================================================================\n",
    "# ==================================== LOADING DATASETS ====================================\n",
    "# ==========================================================================================\n",
    "\n",
    "train_df   = pd.read_csv(\"../Data/train.csv\")\n",
    "test_df    = pd.read_csv(\"../Data/test.csv\")\n",
    "bradley_df = pd.read_excel(\"../Data/helper/BradleyMeltingPointDataset.xlsx\")\n",
    "bradleyplus_df = pd.read_excel(\"../Data/helper/BradleyDoublePlusGoodMeltingPointDataset.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "train_df = train_df[['SMILES', 'Tm']]\n",
    "test_df  = test_df[['id', 'SMILES']]\n",
    "\n",
    "train_df.shape, test_df.shape, bradley_df.shape, bradleyplus_df.shape\n",
    "\n",
    "display(train_df)\n",
    "display(test_df)\n",
    "\n",
    "# ==========================================================================================\n",
    "# ========================== PREPROCESSING EXTERNAL DATA (BRADLEY) =========================\n",
    "# ==========================================================================================\n",
    "\n",
    "# CONVERT MELTING POINT CELCIUS TO KELVIN (Tm)\n",
    "bradley_df['Tm'] = bradley_df['mpC'].map(lambda x : x + 273.15)\n",
    "bradleyplus_df['Tm'] = bradleyplus_df['mpC'].map(lambda x: x + 273.15)\n",
    "\n",
    "# GET ONLY SMILES AND Tm COLUMNS\n",
    "bradley_df = bradley_df[['smiles', 'Tm']]\n",
    "bradleyplus_df = bradleyplus_df[['smiles', 'Tm']]\n",
    "\n",
    "# MERGE THEM\n",
    "bradley_merge = pd.concat((bradley_df, bradleyplus_df), axis = 0)\n",
    "bradley_merge = bradley_merge.rename(columns = {'smiles' : 'SMILES'})\n",
    "\n",
    "bradley_merge\n",
    "\n",
    "# ==========================================================================================\n",
    "# =============================== MERGING AND CLEANING DATA ================================\n",
    "# ==========================================================================================\n",
    "\n",
    "# CONCAT TRAIN DATA AND EXTRA DATA\n",
    "merge_df = pd.concat((train_df, bradley_merge), axis = 0)\n",
    "\n",
    "merge_df\n",
    "\n",
    "# DROP DUPLICATED FROM MERGED DATA\n",
    "display(f'There are {merge_df.duplicated(subset = [\"SMILES\", \"Tm\"]).sum()} Duplicated data')\n",
    "\n",
    "merge_df = merge_df.drop_duplicates(subset = ['SMILES', 'Tm']).reset_index(drop = True)\n",
    "\n",
    "print(f'Successfully Drop Duplicated data!')\n",
    "\n",
    "merge_df\n",
    "\n",
    "# ==========================================================================================\n",
    "# =========================== FEATURE ENGINEERING: DESCRIPTORS =============================\n",
    "# ==========================================================================================\n",
    "\n",
    "# EXTRACT ALL DESCRIPTORS FEATURES\n",
    "def extract_all_descriptors(df, SMILES):\n",
    "\n",
    "    # GET ALL DESCRIPTORS\n",
    "    descriptor_list = Descriptors._descList    # --> THESE WILL RETURN LIST OF TUPLE\n",
    "    descriptors = [desc[0] for desc in descriptor_list]\n",
    "\n",
    "    print(f'There Are {len(descriptor_list)} Descriptor Features')\n",
    "\n",
    "    # EXTRACT ALL DESCRIPTORS FROM SMILES FEATURES\n",
    "    result = []\n",
    "    for smi in df[SMILES]:\n",
    "\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "\n",
    "        # IF MOLECOLE IS INVALID\n",
    "        if mol is None:\n",
    "            row = {name : None for name, func in descriptor_list}\n",
    "        else:\n",
    "            # CREATE DESCRIPTORS FEATURES\n",
    "            row = {name: func(mol) for name, func in descriptor_list}\n",
    "\n",
    "        result.append(row)\n",
    "\n",
    "    # MERGE DATA WITH EXTRACTED FEATURES\n",
    "    df_descriptor = pd.DataFrame(result)\n",
    "    df_result = pd.concat((df, df_descriptor), axis = 1)\n",
    "\n",
    "    return df_result\n",
    "\n",
    "\n",
    "merge_df = extract_all_descriptors(merge_df, 'SMILES')\n",
    "test_df  = extract_all_descriptors(test_df, 'SMILES')\n",
    "\n",
    "# DROP NULL/NONE VALUE AFTER FEATURE ENGINEERING\n",
    "merge_df = merge_df.dropna().reset_index(drop = True)\n",
    "test_df = test_df.dropna().reset_index(drop = True)\n",
    "\n",
    "merge_df\n",
    "\n",
    "# ==========================================================================================\n",
    "# =========================== FEATURE ENGINEERING: FINGERPRINTS ============================\n",
    "# ==========================================================================================\n",
    "\n",
    "# EXTRACT ALL MOLECULAR FINGERPRINT FEATURES\n",
    "def extract_all_fingerprint(df, SMILES, morgan_radius = 2, morgan_nbits = 1024):\n",
    "\n",
    "    fps_data = []  # --> STORE NEW FEATURES DATA\n",
    "\n",
    "    # DEFINE MORGAN GENERATOR\n",
    "    morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius = morgan_radius, fpSize = morgan_nbits, countSimulation = True, includeChirality = False)\n",
    "\n",
    "    fcfp = rdFingerprintGenerator.GetMorganFeatureAtomInvGen()\n",
    "    fcfp_gen = rdFingerprintGenerator.GetMorganGenerator(radius = morgan_nbits, fpSize = morgan_nbits, atomInvariantsGenerator = fcfp, countSimulation= True, includeChirality = False)\n",
    "\n",
    "    atom_gen = rdFingerprintGenerator.GetAtomPairGenerator(fpSize = 2048, countSimulation= True, includeChirality = False)\n",
    "\n",
    "    # ITERATE EVERY SAMPLE OF SMILES FEATURES\n",
    "    for smiles in df[SMILES]:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        if mol is None:\n",
    "            print(smiles, 'is Invalid!')\n",
    "            fps_data.append({})\n",
    "            continue\n",
    "\n",
    "        # STORE NEW FEATURE FOR EACH SAMPLES CREATED\n",
    "        feature_rows = {}\n",
    "\n",
    "        # MORGAN FINGERPRINT (ECFP)\n",
    "        morgan_fp = morgan_gen.GetFingerprint(mol)\n",
    "        for i in range(morgan_nbits):\n",
    "            feature_rows[f\"Morgan_{i}\"] = morgan_fp[i]\n",
    "\n",
    "        # FUNCTIONAL-CLASS FINGERPRINT (FCFP)\n",
    "        fc_fp = fcfp_gen.GetFingerprint(mol)\n",
    "        for i in range(morgan_nbits):\n",
    "            feature_rows[f\"FCFP_{i}\"] = fc_fp[i]\n",
    "\n",
    "        # MACCS KEYS (166 BITS)\n",
    "        maccs_fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "        for i in range(len(maccs_fp)):\n",
    "            feature_rows[f\"MACCS_{i}\"] = int(maccs_fp[i])\n",
    "\n",
    "        # AtomPair Fingerprint (2D)\n",
    "        atompair_fp = atom_gen.GetCountFingerprint(mol)\n",
    "        for i in range(morgan_nbits):\n",
    "            feature_rows[f\"AtomPair_{i}\"] = atompair_fp[i]\n",
    "\n",
    "        # RDKIT FINGERPRINT\n",
    "        rdkit_fp = RDKFingerprint(mol)\n",
    "        for i in range(len(rdkit_fp)):\n",
    "            feature_rows[f\"RDKIT_{i}\"] = int(rdkit_fp[i])\n",
    "\n",
    "        # AVALON FINGERPRINT (IF AVAILABLE) \n",
    "        if avalon_available:\n",
    "            avalon_fp = pyAvalonTools.GetAvalonFP(mol, morgan_nbits)\n",
    "        for i in range(len(avalon_fp)):\n",
    "            feature_rows[f\"Avalon_{i}\"] = int(avalon_fp[i])\n",
    "\n",
    "\n",
    "        fps_data.append(feature_rows)\n",
    "\n",
    "    print(f'There are {morgan_nbits} Morgan Fingerprint Features')\n",
    "    print(f'There are {len(maccs_fp)} MACCS Keys Features')\n",
    "    print(f'There are {len(rdkit_fp)} RDKIT Fingerprint Features')\n",
    "\n",
    "    # MERGE REAL DATA WITH EXTRACTED FEATURES\n",
    "    fps_df = pd.DataFrame(fps_data)\n",
    "    df_result = pd.concat((df, fps_df), axis = 1)\n",
    "\n",
    "    return df_result\n",
    "\n",
    "\n",
    "# APPLY FUNCTION\n",
    "merge_df = extract_all_fingerprint(merge_df, 'SMILES')\n",
    "test_df  = extract_all_fingerprint(test_df, 'SMILES')\n",
    "\n",
    "merge_df\n",
    "\n",
    "# ==========================================================================================\n",
    "# ==================================== DATA SPLITTING ======================================\n",
    "# ==========================================================================================\n",
    "\n",
    "# SPLIT DATA\n",
    "x = merge_df.drop(labels = ['SMILES', 'Tm'], axis = 1)\n",
    "y = merge_df['Tm']\n",
    "\n",
    "x_test = test_df.drop(labels = ['SMILES', 'id'], axis = 1)\n",
    "\n",
    "x.shape, y.shape, x_test.shape, type(x)\n",
    "\n",
    "# ==========================================================================================\n",
    "# =========================== OPTUNA HYPERPARAMETER OPTIMIZATION ===========================\n",
    "# ==========================================================================================\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    xgb_params = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", ['reg:squarederror', 'reg:pseudohubererror']),\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "        'predictor' : 'gpu_predictor',\n",
    "        'device' : 'cuda',\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        'n_estimators' : 10_000,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 3e-3, 0.3, log=True),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.1, 20.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 20.0, log=True),\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 2025)\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(x):\n",
    "        X_train, X_valid = x.iloc[train_idx], x.iloc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "        dvalid = xgboost.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "        model = xgboost.train(\n",
    "            xgb_params,\n",
    "            dtrain,\n",
    "            num_boost_round=10000,\n",
    "            evals=[(dvalid, \"validation\")],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        preds = model.predict(dvalid)\n",
    "        rmse = mean_squared_error(y_valid, preds, squared = False)\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "# START OPTUNA\n",
    "\n",
    "# MOVE AND COPY FILE TO OUPUT\n",
    "shutil.copy(src = '/kaggle/input/optuna-study-3-models/other/optuna-study-3-models/2/xgb_study.db', \n",
    "            dst = '/kaggle/working/xgb_study.db')\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name = 'xgb_study', \n",
    "                            storage=\"sqlite://////kaggle/working/xgb_study.db\", \n",
    "                            load_if_exists = True)\n",
    "\n",
    "# CLEAR OUTPUT AFTER TRAINING \n",
    "clear_output(wait=True)\n",
    "\n",
    "print(f'Training Complete! Congrats!')\n",
    "print(f'Total Number of Trials : {len(study.trials)}\\n')\n",
    "\n",
    "print(\"Best Trial\", study.best_trial.number)\n",
    "print(\"Best MAE:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_trial.params)\n",
    "\n",
    "# ==========================================================================================\n",
    "# ============================ MODEL CONFIGURATION AND PARAMS ==============================\n",
    "# ==========================================================================================\n",
    "\n",
    "# TRAIN XGB WITH BEST PARAMETERS\n",
    "\n",
    "#best_params = study.best_trial.params\n",
    "#best_params.update({'eval_metric' : \"mae\",\n",
    "#                    'device' : 'cpu'})\n",
    "\n",
    "# USE SIMPLER MODEL THAN TUNED MODEL (DUE TO SLOW COMPUTATION)\n",
    "best_params = {\n",
    "    'max_depth' : 6,\n",
    "    'eta' : 0.1,\n",
    "    'tree_method' : 'hist',\n",
    "    'eval_metric' : 'mae'\n",
    "}\n",
    "\n",
    "best_params\n",
    "\n",
    "'''{'objective': 'reg:squarederror',\n",
    " 'max_depth': 3,\n",
    " 'learning_rate': 0.01688021212211354,\n",
    " 'min_child_weight': 5,\n",
    " 'subsample': 0.8943127227676447,\n",
    " 'colsample_bytree': 0.590582609011384,\n",
    " 'gamma': 0.01132850232872052,\n",
    " 'lambda': 4.445806747037075,\n",
    " 'alpha': 0.1292033669407927,\n",
    " 'eval_metric': 'mae',\n",
    " 'device': 'cpu'}'''\n",
    "\n",
    "# ==========================================================================================\n",
    "# ============================== CROSS-VALIDATION TRAINING =================================\n",
    "# ==========================================================================================\n",
    "\n",
    "# XGB WITH SKFOLD\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 2025)\n",
    "\n",
    "# DEFINE YEO-JOHNSON FOR TRANSFORMING TARGET FEATURE INSIDE LOOP\n",
    "yeo = PowerTransformer(method = 'yeo-johnson')\n",
    "\n",
    "# STORE OOF AND TEST MAE\n",
    "oof_val = np.zeros(len(x))\n",
    "train_score , val_score, test_pred = [], [], []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skfold.split(x, pd.qcut(y, q = 10).cat.codes)):\n",
    "    \n",
    "    # SPLIT DATA\n",
    "    x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # USING YEO-JOHNSON TO TRANSFORM TARGET FEATURE\n",
    "    y_train = yeo.fit_transform(y_train.values.reshape(-1, 1)).squeeze()\n",
    "    y_val   = yeo.transform(y_val.values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "    # BUILD TINY CATBOOST TO GET THE MOST IMPORTANT FEATURE ONLY\n",
    "    selector_model = xgboost.XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth = 6,\n",
    "        learning_rate=0.05,\n",
    "        random_state=2025,\n",
    "        device = 'cpu',\n",
    "        objective=\"reg:absoluteerror\",\n",
    "        tree_method = 'hist',\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    # GET THE MOST IMPORTANT FEATURE ONLY \n",
    "    selector_model.fit(x_train, y_train)\n",
    "    selector = SelectFromModel(selector_model, prefit=True, threshold=\"mean\")\n",
    "\n",
    "    # CHECK AND DISPLAY HOW MANY IMPORTANT FEATURES ARE\n",
    "    selected_idx = selector.get_support(indices=True) \n",
    "    selected_features = x_train.columns[selected_idx]\n",
    "    print(\"Selected features:\", len(selected_features),\"\\n\")\n",
    "\n",
    "    # APPLY TRANSFORM (ONLY GET MOST IMPORTANT FEATURE AND REMOVE USELESS FEATURES)\n",
    "    x_train_new = x_train[selected_features]\n",
    "    x_val_new   = x_val[selected_features]\n",
    "    x_test_new  = x_test[selected_features]\n",
    "\n",
    "    # XGBOOST DATASET\n",
    "    dtrain = xgboost.DMatrix(x_train_new, y_train, feature_names = selected_features.tolist())\n",
    "    dval   = xgboost.DMatrix(x_val_new, y_val, feature_names = selected_features.tolist())\n",
    "    dtest  = xgboost.DMatrix(x_test_new, feature_names = selected_features.tolist())\n",
    "\n",
    "    # XGBOOST\n",
    "    xgb = xgboost.train(params = best_params, \n",
    "                        dtrain = dtrain, \n",
    "                        num_boost_round = 15_000, \n",
    "                        evals = [(dtrain, 'train'), (dval, 'valid')],\n",
    "                        early_stopping_rounds = 300,\n",
    "                        verbose_eval = 1000)\n",
    "    \n",
    "    # DISPLAY SELECTED IMPORTANCE FEATURES\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    xgboost.plot_importance(booster = xgb, importance_type = 'gain', max_num_features = 30, ax = ax)\n",
    "    plt.title(f'Feature Importance fold {i+1}')\n",
    "    plt.show()\n",
    "\n",
    "    # PREDICT\n",
    "    y_train_predict = xgb.predict(dtrain)\n",
    "    y_val_predict   = xgb.predict(dval)\n",
    "    y_test_predict = xgb.predict(dtest)\n",
    "\n",
    "    # INVERSE TRANSFORM (TRANSFORM A VALUE BACK TO NORMAL)\n",
    "    y_train = yeo.inverse_transform(y_train.reshape(-1, 1)).squeeze()\n",
    "    y_val   = yeo.inverse_transform(y_val.reshape(-1, 1)).squeeze()\n",
    "    y_train_predict = yeo.inverse_transform(y_train_predict.reshape(-1, 1)).squeeze()\n",
    "    y_val_predict   = yeo.inverse_transform(y_val_predict.reshape(-1, 1)).squeeze()\n",
    "    y_test_predict  = yeo.inverse_transform(y_test_predict.reshape(-1, 1)).squeeze()\n",
    "\n",
    "    # MAE\n",
    "    train_mae = mean_absolute_error(y_train, y_train_predict)\n",
    "    val_mae   = mean_absolute_error(y_val, y_val_predict)\n",
    "\n",
    "    print(f'Fold {i+1} : Train MAE = {train_mae}, Val MAE = {val_mae}')\n",
    "\n",
    "    train_score.append(train_mae)\n",
    "    val_score.append(val_mae)\n",
    "\n",
    "    # PUSH OOF PREDICTION AND TEST PREDICTION\n",
    "    oof_val[val_index] = y_val_predict\n",
    "    test_pred.append(y_test_predict)\n",
    "\n",
    "\n",
    "print(f'\\nTrain Fold Prediction : {np.mean(train_score)}')\n",
    "print(f'Val Fold Prediction   : {np.mean(val_score)}\\n')\n",
    "\n",
    "print(f'std Train Fold Prediction : {np.std(train_score, ddof = 0)}')\n",
    "print(f'std Val Fold Prediction   : {np.std(val_score, ddof = 0)}')\n",
    "\n",
    "# ==========================================================================================\n",
    "# ============================== EVALUATION AND VISUALIZATION ==============================\n",
    "# ==========================================================================================\n",
    "\n",
    "# ACTUAL VS PREDICTED LABEL\n",
    "\n",
    "y_true = merge_df['Tm'].values\n",
    "y_pred = oof_val\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# SCATTER PLOT 2D\n",
    "plt.scatter(y_pred, y_true, alpha=0.7)\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=2)\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Actual vs Predicted')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ==========================================================================================\n",
    "# ============================== OPTUNA PLOTS AND ANALYSIS =================================\n",
    "# ==========================================================================================\n",
    "\n",
    "# SHOW OPTIMIZATION HISTORY \n",
    "optuna.visualization.plot_optimization_history(study) # --> SHOW THE BEST VALUE LINE DURING STUDY\n",
    "\n",
    "# ANALYZE HYPERPARAMETER INTERACTIONS\n",
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "\n",
    "# DISPLAY SENSITIVY EACH PARAMETER\n",
    "optuna.visualization.plot_slice(study)\n",
    "\n",
    "# DISPLAY DECISION BOUNDARY \n",
    "fig = optuna.visualization.plot_contour(study, params=['alpha',\n",
    "                                                 'colsample_bytree',\n",
    "                                                 'gamma',\n",
    "                                                 'lambda',\n",
    "                                                 'learning_rate',\n",
    "                                                 'max_depth'])\n",
    "fig.update_layout(width = 2000, height = 900)\n",
    "\n",
    "# EMPIRICAL DISTRIBUTION\n",
    "optuna.visualization.plot_edf(study) # DISPLAY PROBABILITY OF OBJECTIVE VALUE IS LESS THAN OR EQUAL TO A GIVEN THRESHOLD (EDF CURVE)\n",
    "\n",
    "# DISPLAY HYPERPARAMETER IMPORTANCES\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "\n",
    "# ==========================================================================================\n",
    "# ====================================== SUBMISSION ========================================\n",
    "# ==========================================================================================\n",
    "\n",
    "# SUBMISSION\n",
    "\n",
    "submission = pd.read_csv(r'/kaggle/input/melting-point/sample_submission.csv')\n",
    "\n",
    "submission['Tm'] = np.mean(test_pred, axis = 0)\n",
    "\n",
    "submission\n",
    "\n",
    "# SAVE SUBMISSION\n",
    "submission.to_csv(r'submission_xgb_176460.csv', index = False)\n",
    "\n",
    "# SAVE OOF PREDICTION\n",
    "\n",
    "oof_df = pd.DataFrame(oof_val) # --> CONVERT TO DATAFRAME\n",
    "\n",
    "display(oof_df)\n",
    "\n",
    "# SAVE OOF\n",
    "oof_df.to_csv(r'oof_xgb_176460.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13473948,
     "sourceId": 113155,
     "sourceType": "competition"
    },
    {
     "datasetId": 8364474,
     "sourceId": 13248875,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 456306,
     "modelInstanceId": 439753,
     "sourceId": 588401,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7576.800219,
   "end_time": "2025-11-21T18:41:10.100645",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-21T16:34:53.300426",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
