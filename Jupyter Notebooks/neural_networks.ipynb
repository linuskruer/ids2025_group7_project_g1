{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316aaa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.18\n",
      "  Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow==2.18) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.76.0)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow==2.18)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (3.12.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (3.15.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow==2.18)\n",
      "  Using cached ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (0.31.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.1.2)\n",
      "Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Using cached ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: ml-dtypes, tensorboard, tensorflow\n",
      "\n",
      "  Attempting uninstall: ml-dtypes\n",
      "\n",
      "    Found existing installation: ml_dtypes 0.5.4\n",
      "\n",
      "    Uninstalling ml_dtypes-0.5.4:\n",
      "\n",
      "      Successfully uninstalled ml_dtypes-0.5.4\n",
      "\n",
      "   ---------------------------------------- 0/3 [ml-dtypes]\n",
      "  Attempting uninstall: tensorboard\n",
      "   ---------------------------------------- 0/3 [ml-dtypes]\n",
      "    Found existing installation: tensorboard 2.20.0\n",
      "   ---------------------------------------- 0/3 [ml-dtypes]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "    Uninstalling tensorboard-2.20.0:\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "      Successfully uninstalled tensorboard-2.20.0\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "  Attempting uninstall: tensorflow\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "    Found existing installation: tensorflow 2.20.0\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "    Uninstalling tensorflow-2.20.0:\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "      Successfully uninstalled tensorflow-2.20.0\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   ---------------------------------------- 3/3 [tensorflow]\n",
      "\n",
      "Successfully installed ml-dtypes-0.4.1 tensorboard-2.18.0 tensorflow-2.18.0\n",
      "Requirement already satisfied: pip in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (25.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.18.0)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.9.9)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.76.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (3.15.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (0.1.9)\n",
      "Requirement already satisfied: etils>=1.9.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (1.13.0)\n",
      "Requirement already satisfied: immutabledict in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (4.2.2)\n",
      "Requirement already satisfied: promise in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (7.0.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (22.0.0)\n",
      "Requirement already satisfied: simple_parsing in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (1.17.2)\n",
      "Requirement already satisfied: toml in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (4.67.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: einops in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (0.8.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2025.10.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (6.5.2)\n",
      "Requirement already satisfied: zipp in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.23.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dm-tree->tensorflow_datasets) (25.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from simple_parsing->tensorflow_datasets) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.72.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hwind\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->tensorflow_datasets) (0.4.6)\n",
      "Using cached tensorflow-2.20.0-cp311-cp311-win_amd64.whl (331.8 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl (210 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: ml_dtypes, tensorboard, tensorflow\n",
      "\n",
      "  Attempting uninstall: ml_dtypes\n",
      "\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "\n",
      "   ---------------------------------------- 0/3 [ml_dtypes]\n",
      "  Attempting uninstall: tensorboard\n",
      "   ---------------------------------------- 0/3 [ml_dtypes]\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "   ---------------------------------------- 0/3 [ml_dtypes]\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "   ---------------------------------------- 0/3 [ml_dtypes]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "  Attempting uninstall: tensorflow\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   ---------------------------------------- 3/3 [tensorflow]\n",
      "\n",
      "Successfully installed ml_dtypes-0.5.4 tensorboard-2.20.0 tensorflow-2.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.4 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.18\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade tensorflow tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef2f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwind\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def featurize_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(2050)\n",
    "\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    hbd = Descriptors.NumHDonors(mol)\n",
    "    hba = Descriptors.NumHAcceptors(mol)\n",
    "    tpsa = Descriptors.TPSA(mol)\n",
    "\n",
    "    fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    fp = np.array(fp)\n",
    "\n",
    "    return np.concatenate([[mw, logp, hbd, hba, tpsa], fp])\n",
    "train = pd.read_csv(\"/Users/hwind/Downloads/Python/Master/3_Semester/Data Science/Project/ids2025_group7_project_g1/Data/train.csv\")\n",
    "test = pd.read_csv(\"/Users/hwind/Downloads/Python/Master/3_Semester/Data Science/Project/ids2025_group7_project_g1/Data/test.csv\")\n",
    "\n",
    "X_train = np.vstack(train[\"SMILES\"].apply(featurize_smiles)).astype('float32')\n",
    "X_test = np.vstack(test[\"SMILES\"].apply(featurize_smiles)).astype('float32')\n",
    "y_train = train[\"Tm\"].values.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b7cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x dtype: <dtype: 'float32'>\n",
      "weights dtype: <dtype: 'float32'>\n",
      "Epoch 01  Loss: 62879.6445\n",
      "Epoch 02  Loss: 16652.4062\n",
      "Epoch 03  Loss: 9554.9199\n",
      "Epoch 04  Loss: 8207.5371\n",
      "Epoch 05  Loss: 7488.8682\n",
      "Epoch 06  Loss: 7045.9912\n",
      "Epoch 07  Loss: 6582.2388\n",
      "Epoch 08  Loss: 6197.9004\n",
      "Epoch 09  Loss: 5769.0342\n",
      "Epoch 10  Loss: 5336.4146\n",
      "Epoch 11  Loss: 4908.9102\n",
      "Epoch 12  Loss: 4550.9663\n",
      "Epoch 13  Loss: 4179.8125\n",
      "Epoch 14  Loss: 3874.0027\n",
      "Epoch 15  Loss: 3631.7195\n",
      "Epoch 16  Loss: 3419.2173\n",
      "Epoch 17  Loss: 3205.6108\n",
      "Epoch 18  Loss: 3088.6477\n",
      "Epoch 19  Loss: 2868.0762\n",
      "Epoch 20  Loss: 2751.9890\n",
      "\n",
      "Beispielvorhersagen: [333.62216 382.12903 180.07803 192.65445 242.0797 ]\n"
     ]
    }
   ],
   "source": [
    "num_features = X_train.shape[1]\n",
    "batch_size = 128\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_train.astype('float32'), y_train.astype('float32')))\n",
    "ds_train = ds_train.shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "initializer = tf.initializers.GlorotUniform()\n",
    "\n",
    "weights = {\n",
    "    \"h1\": tf.Variable(initializer([num_features, n_hidden_1], dtype=tf.float32)),\n",
    "    \"h2\": tf.Variable(initializer([n_hidden_1, n_hidden_2], dtype=tf.float32)),\n",
    "    \"out\": tf.Variable(initializer([n_hidden_2, 1], dtype=tf.float32))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b1\": tf.Variable(tf.zeros([n_hidden_1], dtype=tf.float32)),\n",
    "    \"b2\": tf.Variable(tf.zeros([n_hidden_2], dtype=tf.float32)),\n",
    "    \"out\": tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6) Modell (wie im MNIST Code)\n",
    "# ------------------------------------------------------\n",
    "def neural_net(x):\n",
    "    layer1 = tf.nn.relu(tf.matmul(x, weights[\"h1\"]) + biases[\"b1\"])\n",
    "    layer2 = tf.nn.relu(tf.matmul(layer1, weights[\"h2\"]) + biases[\"b2\"])\n",
    "    out = tf.matmul(layer2, weights[\"out\"]) + biases[\"out\"]  # LINEARER OUTPUT\n",
    "    return out  # shape: (batch, 1)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 7) Loss + Optimizer\n",
    "# ------------------------------------------------------\n",
    "def mse_loss(y_pred, y_true):\n",
    "    y_true = tf.reshape(y_true, (-1, 1))\n",
    "    return tf.reduce_mean((y_true - y_pred) ** 2)\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "print(\"x dtype:\", bx.dtype)\n",
    "print(\"weights dtype:\", weights[\"h1\"].dtype)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 8) Trainingsschritt\n",
    "# ------------------------------------------------------\n",
    "def run_optimization(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = neural_net(x)\n",
    "        loss = mse_loss(pred, y)\n",
    "\n",
    "    trainable_vars = list(weights.values()) + list(biases.values())\n",
    "    gradients = tape.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 9) Training\n",
    "# ------------------------------------------------------\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    batch_losses = []\n",
    "    for bx, by in ds_train:\n",
    "        loss = run_optimization(bx, by)\n",
    "        batch_losses.append(loss.numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}  Loss: {np.mean(batch_losses):.4f}\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 10) Vorhersage fr Testdaten\n",
    "# ------------------------------------------------------\n",
    "pred_test = neural_net(X_test).numpy().flatten()\n",
    "\n",
    "print(\"\\nBeispielvorhersagen:\", pred_test[:5])\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"Tm\": pred_test\n",
    "})\n",
    "\n",
    "submission.to_csv(\"Submissions/predictions_NN.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6eec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 79581.6016\n",
      "Epoch 2/300\n",
      "\u001b[1m 8/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 76229.2686"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwind\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\callbacks\\early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 69291.6953\n",
      "Epoch 3/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 51001.1953\n",
      "Epoch 4/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 29023.6270\n",
      "Epoch 5/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 14675.5068\n",
      "Epoch 6/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8527.5811\n",
      "Epoch 7/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6012.7163\n",
      "Epoch 8/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5241.3262\n",
      "Epoch 9/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4250.9004\n",
      "Epoch 10/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3834.4275\n",
      "Epoch 11/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2855.1746\n",
      "Epoch 12/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2599.3091\n",
      "Epoch 13/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2167.2104\n",
      "Epoch 14/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2135.0894\n",
      "Epoch 15/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2225.0964\n",
      "Epoch 16/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2081.5317\n",
      "Epoch 17/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1985.2156\n",
      "Epoch 18/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1964.6011\n",
      "Epoch 19/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1872.4188\n",
      "Epoch 20/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2179.1853\n",
      "Epoch 21/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1688.9624\n",
      "Epoch 22/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1527.4949\n",
      "Epoch 23/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1557.6053\n",
      "Epoch 24/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1595.5372\n",
      "Epoch 25/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1059.5557\n",
      "Epoch 26/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1121.3226\n",
      "Epoch 27/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1047.1290\n",
      "Epoch 28/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1251.8032\n",
      "Epoch 29/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1116.9258\n",
      "Epoch 30/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 997.1124\n",
      "Epoch 31/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1013.7001\n",
      "Epoch 32/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1123.6217\n",
      "Epoch 33/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 941.1811 \n",
      "Epoch 34/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1010.5608\n",
      "Epoch 35/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 917.5197\n",
      "Epoch 36/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 957.7659 \n",
      "Epoch 37/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 913.3228\n",
      "Epoch 38/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1073.0927\n",
      "Epoch 39/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 980.8358 \n",
      "Epoch 40/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 886.1459\n",
      "Epoch 41/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1030.3123\n",
      "Epoch 42/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 947.0052 \n",
      "Epoch 43/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1147.0217\n",
      "Epoch 44/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1136.7346\n",
      "Epoch 45/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1005.7733\n",
      "Epoch 46/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 924.4033\n",
      "Epoch 47/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 942.3441\n",
      "Epoch 48/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 650.9885\n",
      "Epoch 49/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 771.2729\n",
      "Epoch 50/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 722.5520\n",
      "Epoch 51/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 763.8443\n",
      "Epoch 52/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 870.2198\n",
      "Epoch 53/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 807.5479\n",
      "Epoch 54/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 791.0649\n",
      "Epoch 55/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 717.6949\n",
      "Epoch 56/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 795.0840\n",
      "Epoch 57/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 750.8516\n",
      "Epoch 58/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 652.7387\n",
      "Epoch 59/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 554.6669\n",
      "Epoch 60/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 872.8079\n",
      "Epoch 61/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 676.0671\n",
      "Epoch 62/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 604.2161\n",
      "Epoch 63/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 644.8739\n",
      "Epoch 64/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 698.3681\n",
      "Epoch 65/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 818.3530\n",
      "Epoch 66/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 574.7742\n",
      "Epoch 67/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 538.7031\n",
      "Epoch 68/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 612.9529\n",
      "Epoch 69/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 569.6409\n",
      "Epoch 70/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 422.9725\n",
      "Epoch 71/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 482.9398\n",
      "Epoch 72/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 482.5272\n",
      "Epoch 73/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 484.2747\n",
      "Epoch 74/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 535.9279\n",
      "Epoch 75/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 628.5198\n",
      "Epoch 76/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 727.4796\n",
      "Epoch 77/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 517.1549\n",
      "Epoch 78/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 489.4351\n",
      "Epoch 79/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 567.9654\n",
      "Epoch 80/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 524.9954\n",
      "Epoch 81/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 480.7553\n",
      "Epoch 82/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 552.2878\n",
      "Epoch 83/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 419.9232\n",
      "Epoch 84/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 411.1247\n",
      "Epoch 85/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 491.3634\n",
      "Epoch 86/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 409.8000\n",
      "Epoch 87/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 392.1419\n",
      "Epoch 88/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 523.3206\n",
      "Epoch 89/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 488.6875\n",
      "Epoch 90/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 439.3555\n",
      "Epoch 91/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 468.5387\n",
      "Epoch 92/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 394.0757\n",
      "Epoch 93/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 400.8099\n",
      "Epoch 94/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 353.8761\n",
      "Epoch 95/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 341.5047\n",
      "Epoch 96/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 408.1438\n",
      "Epoch 97/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 461.0549\n",
      "Epoch 98/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 409.2104\n",
      "Epoch 99/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 381.9617\n",
      "Epoch 100/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 396.3572\n",
      "Epoch 101/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 420.5757\n",
      "Epoch 102/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 351.9587\n",
      "Epoch 103/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 364.8939\n",
      "Epoch 104/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 315.8532\n",
      "Epoch 105/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 361.2250\n",
      "Epoch 106/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 418.5923\n",
      "Epoch 107/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 351.9416\n",
      "Epoch 108/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 433.3196\n",
      "Epoch 109/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 461.7891\n",
      "Epoch 110/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 441.1395\n",
      "Epoch 111/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 383.7098\n",
      "Epoch 112/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 314.9007\n",
      "Epoch 113/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 348.7249\n",
      "Epoch 114/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 325.0288\n",
      "Epoch 115/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 333.5118\n",
      "Epoch 116/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 330.9070\n",
      "Epoch 117/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 331.2525\n",
      "Epoch 118/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 366.9710\n",
      "Epoch 119/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 321.2356\n",
      "Epoch 120/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 285.1104\n",
      "Epoch 121/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 344.8846\n",
      "Epoch 122/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 311.7629\n",
      "Epoch 123/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 339.3457\n",
      "Epoch 124/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 338.5915\n",
      "Epoch 125/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 298.6864\n",
      "Epoch 126/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 270.8167\n",
      "Epoch 127/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 271.0919\n",
      "Epoch 128/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 330.9163\n",
      "Epoch 129/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 344.8802\n",
      "Epoch 130/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 246.2043\n",
      "Epoch 131/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 269.6461\n",
      "Epoch 132/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 263.3364\n",
      "Epoch 133/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 256.4391\n",
      "Epoch 134/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 298.7045\n",
      "Epoch 135/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 265.7046\n",
      "Epoch 136/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 317.0196\n",
      "Epoch 137/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 393.8267\n",
      "Epoch 138/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 334.2117\n",
      "Epoch 139/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 363.1301\n",
      "Epoch 140/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 420.5352\n",
      "Epoch 141/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 296.0601\n",
      "Epoch 142/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 254.8606\n",
      "Epoch 143/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 292.5787\n",
      "Epoch 144/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 288.9972\n",
      "Epoch 145/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 314.1763\n",
      "Epoch 146/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 313.6123\n",
      "Epoch 147/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 277.6163\n",
      "Epoch 148/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 272.3911\n",
      "Epoch 149/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 292.7742\n",
      "Epoch 150/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 285.6246\n",
      "Epoch 151/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 323.6310\n",
      "Epoch 152/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 241.1505\n",
      "Epoch 153/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 259.8344\n",
      "Epoch 154/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 266.2869\n",
      "Epoch 155/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 251.6487\n",
      "Epoch 156/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 261.9731\n",
      "Epoch 157/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 241.5798\n",
      "Epoch 158/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 266.0368\n",
      "Epoch 159/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 297.7652\n",
      "Epoch 160/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 329.9424\n",
      "Epoch 161/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 248.4506\n",
      "Epoch 162/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 310.7921\n",
      "Epoch 163/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 253.3806\n",
      "Epoch 164/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 214.0154\n",
      "Epoch 165/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 265.8199\n",
      "Epoch 166/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 195.9265\n",
      "Epoch 167/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 215.6146\n",
      "Epoch 168/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 244.9935\n",
      "Epoch 169/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 297.2008\n",
      "Epoch 170/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 342.1713\n",
      "Epoch 171/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 227.7702\n",
      "Epoch 172/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 301.5414\n",
      "Epoch 173/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 255.9893\n",
      "Epoch 174/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 213.1213\n",
      "Epoch 175/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 234.2543\n",
      "Epoch 176/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 268.8084\n",
      "Epoch 177/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 273.1960\n",
      "Epoch 178/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 260.0628\n",
      "Epoch 179/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 265.5540\n",
      "Epoch 180/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 247.9703\n",
      "Epoch 181/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 199.3705\n",
      "Epoch 182/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 233.8805\n",
      "Epoch 183/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 317.0923\n",
      "Epoch 184/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 234.7603\n",
      "Epoch 185/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 274.8592\n",
      "Epoch 186/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 252.5010\n",
      "Epoch 187/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 245.4538\n",
      "Epoch 188/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 258.8142\n",
      "Epoch 189/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 312.0587\n",
      "Epoch 190/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 229.8590\n",
      "Epoch 191/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 259.5763\n",
      "Epoch 192/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 218.6349\n",
      "Epoch 193/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 171.9287\n",
      "Epoch 194/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 163.8155\n",
      "Epoch 195/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 207.2836\n",
      "Epoch 196/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 249.1842\n",
      "Epoch 197/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 220.4246\n",
      "Epoch 198/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 238.1858\n",
      "Epoch 199/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 240.8656\n",
      "Epoch 200/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 219.2996\n",
      "Epoch 201/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 292.4516\n",
      "Epoch 202/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 432.0442\n",
      "Epoch 203/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 374.9429\n",
      "Epoch 204/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 284.7990\n",
      "Epoch 205/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 226.1851\n",
      "Epoch 206/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 235.6275\n",
      "Epoch 207/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 196.2194\n",
      "Epoch 208/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 281.2225\n",
      "Epoch 209/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 240.4006\n",
      "Epoch 210/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 215.5061\n",
      "Epoch 211/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 184.1760\n",
      "Epoch 212/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 247.1787\n",
      "Epoch 213/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 259.3662\n",
      "Epoch 214/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 206.3279\n",
      "Epoch 215/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 256.3176\n",
      "Epoch 216/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 235.4839\n",
      "Epoch 217/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 269.3629\n",
      "Epoch 218/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 231.3446\n",
      "Epoch 219/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 314.1924\n",
      "Epoch 220/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 274.7617\n",
      "Epoch 221/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 267.6416\n",
      "Epoch 222/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 217.9546\n",
      "Epoch 223/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 202.2637\n",
      "Epoch 224/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 189.8979\n",
      "Epoch 225/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 190.6930\n",
      "Epoch 226/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 155.8955\n",
      "Epoch 227/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 151.6166\n",
      "Epoch 228/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 162.3717\n",
      "Epoch 229/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 273.1449\n",
      "Epoch 230/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 212.9755\n",
      "Epoch 231/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 185.2033\n",
      "Epoch 232/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 215.9372\n",
      "Epoch 233/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 179.5899\n",
      "Epoch 234/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 175.4579\n",
      "Epoch 235/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 188.0835\n",
      "Epoch 236/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 168.7319\n",
      "Epoch 237/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 188.7271\n",
      "Epoch 238/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 219.8867\n",
      "Epoch 239/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 188.1762\n",
      "Epoch 240/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 183.8562\n",
      "Epoch 241/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 228.9282\n",
      "Epoch 242/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 175.4466\n",
      "Epoch 243/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 195.7849\n",
      "Epoch 244/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 256.8434\n",
      "Epoch 245/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 341.5598\n",
      "Epoch 246/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 265.6029\n",
      "Epoch 247/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 197.3411\n",
      "Epoch 248/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 191.1997\n",
      "Epoch 249/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 197.4353\n",
      "Epoch 250/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 165.1849\n",
      "Epoch 251/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 147.3738\n",
      "Epoch 252/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 168.3955\n",
      "Epoch 253/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 196.9555\n",
      "Epoch 254/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 249.5477\n",
      "Epoch 255/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 251.4549\n",
      "Epoch 256/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 202.5748\n",
      "Epoch 257/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 221.2997\n",
      "Epoch 258/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 181.1184\n",
      "Epoch 259/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 239.9288\n",
      "Epoch 260/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 230.4086\n",
      "Epoch 261/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 163.9459\n",
      "Epoch 262/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 189.8365\n",
      "Epoch 263/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 169.2018\n",
      "Epoch 264/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 139.3243\n",
      "Epoch 265/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 185.9594\n",
      "Epoch 266/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 172.3169\n",
      "Epoch 267/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 176.0927\n",
      "Epoch 268/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 180.5455\n",
      "Epoch 269/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 173.1832\n",
      "Epoch 270/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 163.4846\n",
      "Epoch 271/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 208.2091\n",
      "Epoch 272/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 204.6072\n",
      "Epoch 273/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 172.7932\n",
      "Epoch 274/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 187.8506\n",
      "Epoch 275/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 219.5192\n",
      "Epoch 276/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 197.5248\n",
      "Epoch 277/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 179.8871\n",
      "Epoch 278/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 176.0248\n",
      "Epoch 279/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 175.3142\n",
      "Epoch 280/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 177.9823\n",
      "Epoch 281/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 178.8083\n",
      "Epoch 282/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 159.4758\n",
      "Epoch 283/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 142.4426\n",
      "Epoch 284/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 139.6298\n",
      "Epoch 285/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 137.8182\n",
      "Epoch 286/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 141.3449\n",
      "Epoch 287/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 148.4650\n",
      "Epoch 288/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 165.1138\n",
      "Epoch 289/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 186.4173\n",
      "Epoch 290/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 196.7915\n",
      "Epoch 291/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 177.8206\n",
      "Epoch 292/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 338.2084\n",
      "Epoch 293/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 274.1287\n",
      "Epoch 294/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 287.9037\n",
      "Epoch 295/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 289.3457\n",
      "Epoch 296/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 287.6851\n",
      "Epoch 297/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 228.5679\n",
      "Epoch 298/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 206.9607\n",
      "Epoch 299/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 250.5657\n",
      "Epoch 300/300\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 184.0913\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "#best try\n",
    "# ----------------------\n",
    "# 2) TensorFlow Dataset\n",
    "# ----------------------\n",
    "batch_size = 128\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train.astype(\"float32\")))\n",
    "ds_train = ds_train.shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ----------------------\n",
    "# 3) Besseres Modell\n",
    "# ----------------------\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(num_features,)),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)  # linear output\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"mse\"\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 4) Training\n",
    "# ----------------------\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=30,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=300,\n",
    "    callbacks=[callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 5) Predictions + CSV\n",
    "# ----------------------\n",
    "pred_test = model.predict(X_test).flatten()\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"Tm\": pred_test\n",
    "}).to_csv(\"Submissions/predictions_NN_improved.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8259c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Modell mit Seed 0\n",
      "Epoch 1/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 70730.2109 - val_loss: 27424.1230\n",
      "Epoch 2/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 19739.2109 - val_loss: 21232.5566\n",
      "Epoch 3/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 4302.8271 - val_loss: 12698.2559\n",
      "Epoch 4/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 3072.2620 - val_loss: 8251.7139\n",
      "Epoch 5/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 2581.8643 - val_loss: 12107.0186\n",
      "Epoch 6/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 2313.0667 - val_loss: 14560.8936\n",
      "Epoch 7/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 2194.8135 - val_loss: 10525.7539\n",
      "Epoch 8/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 2006.3696 - val_loss: 15301.4199\n",
      "Epoch 9/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1847.5421 - val_loss: 11848.7734\n",
      "Epoch 10/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1842.1168 - val_loss: 14655.4834\n",
      "Epoch 11/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1678.7551 - val_loss: 14224.0459\n",
      "Epoch 12/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1778.0909 - val_loss: 17925.6875\n",
      "Epoch 13/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1608.6398 - val_loss: 17589.5488\n",
      "Epoch 14/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1248.4038 - val_loss: 15058.2559\n",
      "Epoch 15/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1251.3424 - val_loss: 13694.8184\n",
      "Epoch 16/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1325.6903 - val_loss: 13397.3760\n",
      "Epoch 17/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1195.4220 - val_loss: 13834.6016\n",
      "Epoch 18/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1029.0475 - val_loss: 14087.6758\n",
      "Epoch 19/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1463.3258 - val_loss: 13011.7344\n",
      "Epoch 20/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1181.0103 - val_loss: 12110.1533\n",
      "Epoch 21/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1314.1099 - val_loss: 10127.2822\n",
      "Epoch 22/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1107.8290 - val_loss: 10749.6943\n",
      "Epoch 23/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1122.3704 - val_loss: 9686.8994\n",
      "Epoch 24/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 958.5621 - val_loss: 9526.3975\n",
      "Epoch 25/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 970.7987 - val_loss: 11837.4902\n",
      "Epoch 26/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 994.7163 - val_loss: 10982.8877\n",
      "Epoch 27/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 917.5441 - val_loss: 8875.1592\n",
      "Epoch 28/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 1074.5192 - val_loss: 12492.9648\n",
      "Epoch 29/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1205.3521 - val_loss: 12385.8438\n",
      "Epoch 30/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 921.4669 - val_loss: 9421.3730\n",
      "Epoch 31/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 857.1061 - val_loss: 8205.8477\n",
      "Epoch 32/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 900.1940 - val_loss: 6787.5791\n",
      "Epoch 33/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 942.1885 - val_loss: 11796.4658\n",
      "Epoch 34/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 874.9032 - val_loss: 10464.0986\n",
      "Epoch 35/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 793.2258 - val_loss: 8890.3838\n",
      "Epoch 36/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 907.6013 - val_loss: 8292.5527\n",
      "Epoch 37/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 785.1457 - val_loss: 10767.5049\n",
      "Epoch 38/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 822.5323 - val_loss: 9945.6895\n",
      "Epoch 39/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 904.8193 - val_loss: 8831.5312\n",
      "Epoch 40/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 847.4575 - val_loss: 7681.9341\n",
      "Epoch 41/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 995.1390 - val_loss: 6158.7544\n",
      "Epoch 42/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 769.1811 - val_loss: 5495.6567\n",
      "Epoch 43/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1019.9928 - val_loss: 4974.0068\n",
      "Epoch 44/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 795.1561 - val_loss: 6767.3940\n",
      "Epoch 45/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 757.3107 - val_loss: 6557.7705\n",
      "Epoch 46/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 845.8287 - val_loss: 5022.1621\n",
      "Epoch 47/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 810.8166 - val_loss: 7343.5981\n",
      "Epoch 48/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 734.0940 - val_loss: 5324.0879\n",
      "Epoch 49/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 630.6247 - val_loss: 8014.8213\n",
      "Epoch 50/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 697.0270 - val_loss: 5159.9487\n",
      "Epoch 51/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 668.1395 - val_loss: 6162.8135\n",
      "Epoch 52/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 603.0339 - val_loss: 4289.1230\n",
      "Epoch 53/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 641.7728 - val_loss: 4949.9458\n",
      "Epoch 54/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 687.6954 - val_loss: 5446.9497\n",
      "Epoch 55/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 774.7261 - val_loss: 4733.4146\n",
      "Epoch 56/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 726.7871 - val_loss: 5262.9795\n",
      "Epoch 57/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 651.7909 - val_loss: 3488.7886\n",
      "Epoch 58/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 569.8243 - val_loss: 3267.9834\n",
      "Epoch 59/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 612.6075 - val_loss: 4712.0308\n",
      "Epoch 60/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 576.3602 - val_loss: 3359.9197\n",
      "Epoch 61/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 596.5141 - val_loss: 3558.6812\n",
      "Epoch 62/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 565.1302 - val_loss: 3310.7456\n",
      "Epoch 63/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 533.5656 - val_loss: 3530.9436\n",
      "Epoch 64/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 553.0183 - val_loss: 3723.9592\n",
      "Epoch 65/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 559.3218 - val_loss: 2783.8259\n",
      "Epoch 66/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 491.3727 - val_loss: 2712.4016\n",
      "Epoch 67/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 534.8820 - val_loss: 2960.0974\n",
      "Epoch 68/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 486.9979 - val_loss: 2695.5378\n",
      "Epoch 69/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 529.5602 - val_loss: 2707.3708\n",
      "Epoch 70/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 582.3804 - val_loss: 3168.9045\n",
      "Epoch 71/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 594.4581 - val_loss: 2583.3267\n",
      "Epoch 72/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 569.3926 - val_loss: 2510.6873\n",
      "Epoch 73/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 571.0333 - val_loss: 2632.1545\n",
      "Epoch 74/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 526.3847 - val_loss: 2607.4924\n",
      "Epoch 75/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 447.7620 - val_loss: 2409.2678\n",
      "Epoch 76/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 452.1661 - val_loss: 2431.5325\n",
      "Epoch 77/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 453.4628 - val_loss: 2939.9502\n",
      "Epoch 78/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 499.6079 - val_loss: 2552.1145\n",
      "Epoch 79/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 530.7202 - val_loss: 2483.2722\n",
      "Epoch 80/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 481.5310 - val_loss: 2516.3530\n",
      "Epoch 81/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 560.6365 - val_loss: 2586.3635\n",
      "Epoch 82/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 467.4586 - val_loss: 2710.8052\n",
      "Epoch 83/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 437.0871 - val_loss: 2596.6929\n",
      "Epoch 84/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 409.6977 - val_loss: 2506.2200\n",
      "Epoch 85/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 472.6419 - val_loss: 2401.2034\n",
      "Epoch 86/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 392.6539 - val_loss: 2332.0142\n",
      "Epoch 87/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 385.9339 - val_loss: 2468.0999\n",
      "Epoch 88/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 430.0617 - val_loss: 2450.6978\n",
      "Epoch 89/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 450.1032 - val_loss: 2681.9990\n",
      "Epoch 90/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 449.7249 - val_loss: 2362.7800\n",
      "Epoch 91/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 437.1057 - val_loss: 2633.1580\n",
      "Epoch 92/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 372.2585 - val_loss: 2513.3245\n",
      "Epoch 93/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 391.4570 - val_loss: 2472.1304\n",
      "Epoch 94/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 428.7643 - val_loss: 2479.0173\n",
      "Epoch 95/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 371.7389 - val_loss: 2524.2253\n",
      "Epoch 96/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 432.8071 - val_loss: 2424.6677\n",
      "Epoch 97/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 428.6372 - val_loss: 2448.5229\n",
      "Epoch 98/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 390.8153 - val_loss: 2494.9148\n",
      "Epoch 99/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 413.6137 - val_loss: 2498.2109\n",
      "Epoch 100/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 343.1040 - val_loss: 2500.4490\n",
      "Epoch 101/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 359.3102 - val_loss: 2427.3477\n",
      "Epoch 102/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 371.1071 - val_loss: 2431.7283\n",
      "Epoch 103/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 417.6649 - val_loss: 2588.0337\n",
      "Epoch 104/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 375.6508 - val_loss: 2409.8250\n",
      "Epoch 105/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 381.8033 - val_loss: 2383.9199\n",
      "Epoch 106/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 350.5087 - val_loss: 2465.3450\n",
      "Epoch 107/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 371.4276 - val_loss: 2437.4072\n",
      "Epoch 108/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 340.6997 - val_loss: 2495.5996\n",
      "Epoch 109/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 359.8963 - val_loss: 2490.5535\n",
      "Epoch 110/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 361.2978 - val_loss: 2478.3044\n",
      "Epoch 111/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 374.3937 - val_loss: 2474.1221\n",
      "Epoch 112/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 373.4795 - val_loss: 2469.0608\n",
      "Epoch 113/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 375.6228 - val_loss: 2485.7874\n",
      "Epoch 114/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 355.0995 - val_loss: 2521.9067\n",
      "Epoch 115/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 399.8335 - val_loss: 2582.3015\n",
      "Epoch 116/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 343.2437 - val_loss: 2533.3652\n",
      "Epoch 117/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 360.1141 - val_loss: 2512.3735\n",
      "Epoch 118/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 365.1520 - val_loss: 2502.1611\n",
      "Epoch 119/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 357.9861 - val_loss: 2488.2136\n",
      "Epoch 120/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 319.6919 - val_loss: 2493.6760\n",
      "Epoch 121/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 312.9299 - val_loss: 2486.6826\n",
      "Epoch 122/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 323.0359 - val_loss: 2481.9487\n",
      "Epoch 123/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 359.2944 - val_loss: 2461.8064\n",
      "Epoch 124/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 329.7554 - val_loss: 2463.1406\n",
      "Epoch 125/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 410.4568 - val_loss: 2485.1658\n",
      "Epoch 126/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 331.8590 - val_loss: 2485.7493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "\n",
      " Training Modell mit Seed 1\n",
      "Epoch 1/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - loss: 69368.8281 - val_loss: 41463.1445\n",
      "Epoch 2/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 18366.2734 - val_loss: 13569.3281\n",
      "Epoch 3/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 4195.1216 - val_loss: 6991.7129\n",
      "Epoch 4/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 3002.7974 - val_loss: 13368.5693\n",
      "Epoch 5/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 2568.4644 - val_loss: 14298.9951\n",
      "Epoch 6/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 2502.3923 - val_loss: 13575.8730\n",
      "Epoch 7/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 2358.2791 - val_loss: 14117.7021\n",
      "Epoch 8/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1858.4626 - val_loss: 14115.5352\n",
      "Epoch 9/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1584.0785 - val_loss: 12171.6064\n",
      "Epoch 10/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1676.4441 - val_loss: 14467.5127\n",
      "Epoch 11/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1445.2200 - val_loss: 15299.7715\n",
      "Epoch 12/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1424.1263 - val_loss: 13021.1895\n",
      "Epoch 13/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1864.6001 - val_loss: 9541.3066\n",
      "Epoch 14/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1374.6809 - val_loss: 10547.4912\n",
      "Epoch 15/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1282.1267 - val_loss: 11969.7080\n",
      "Epoch 16/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1399.5481 - val_loss: 9024.1953\n",
      "Epoch 17/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1146.4110 - val_loss: 9105.4473\n",
      "Epoch 18/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1160.1355 - val_loss: 10824.7686\n",
      "Epoch 19/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1208.1287 - val_loss: 11468.5625\n",
      "Epoch 20/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1307.2085 - val_loss: 6169.4917\n",
      "Epoch 21/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1241.0117 - val_loss: 10968.6719\n",
      "Epoch 22/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1294.5352 - val_loss: 9093.7178\n",
      "Epoch 23/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 966.7220 - val_loss: 12136.1328\n",
      "Epoch 24/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1041.6884 - val_loss: 9885.4688\n",
      "Epoch 25/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1099.5814 - val_loss: 12234.6553\n",
      "Epoch 26/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1117.3500 - val_loss: 8539.3438\n",
      "Epoch 27/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1111.7087 - val_loss: 9498.3770\n",
      "Epoch 28/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 934.3201 - val_loss: 8781.3555\n",
      "Epoch 29/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1042.8103 - val_loss: 7445.8975\n",
      "Epoch 30/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 872.4200 - val_loss: 8819.8848\n",
      "Epoch 31/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1068.7489 - val_loss: 6913.3687\n",
      "Epoch 32/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 993.6974 - val_loss: 11315.5312\n",
      "Epoch 33/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 912.6268 - val_loss: 12328.0166\n",
      "Epoch 34/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 943.6285 - val_loss: 9239.1299\n",
      "Epoch 35/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 920.3491 - val_loss: 11305.9814\n",
      "Epoch 36/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 937.7353 - val_loss: 11814.1787\n",
      "Epoch 37/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 868.7676 - val_loss: 11781.7441\n",
      "Epoch 38/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 819.2148 - val_loss: 11477.6816\n",
      "Epoch 39/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 935.3608 - val_loss: 6173.6963\n",
      "Epoch 40/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 906.7836 - val_loss: 7794.6147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
      "\n",
      " Training Modell mit Seed 2\n",
      "Epoch 1/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - loss: 68010.5312 - val_loss: 40644.1484\n",
      "Epoch 2/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 15839.2598 - val_loss: 29136.9219\n",
      "Epoch 3/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 4223.9507 - val_loss: 8824.6631\n",
      "Epoch 4/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 2987.4431 - val_loss: 16794.7891\n",
      "Epoch 5/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 2423.8997 - val_loss: 8558.5098\n",
      "Epoch 6/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 2270.5361 - val_loss: 13093.7383\n",
      "Epoch 7/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1977.1494 - val_loss: 15246.8926\n",
      "Epoch 8/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1667.0808 - val_loss: 9318.1445\n",
      "Epoch 9/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1650.9053 - val_loss: 12180.1240\n",
      "Epoch 10/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 1592.6587 - val_loss: 13373.1094\n",
      "Epoch 11/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1581.4468 - val_loss: 11416.7734\n",
      "Epoch 12/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1523.5436 - val_loss: 10896.3760\n",
      "Epoch 13/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1440.9534 - val_loss: 9944.3154\n",
      "Epoch 14/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 1316.8888 - val_loss: 13501.3818\n",
      "Epoch 15/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1378.1735 - val_loss: 10526.7969\n",
      "Epoch 16/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1068.3298 - val_loss: 9750.8896\n",
      "Epoch 17/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1093.0353 - val_loss: 9002.8955\n",
      "Epoch 18/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1194.1559 - val_loss: 11490.3936\n",
      "Epoch 19/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1198.3187 - val_loss: 8852.9873\n",
      "Epoch 20/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1093.4913 - val_loss: 10239.0146\n",
      "Epoch 21/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 986.8110 - val_loss: 11151.0918\n",
      "Epoch 22/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1059.1211 - val_loss: 9486.6816\n",
      "Epoch 23/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1177.2140 - val_loss: 11703.5977\n",
      "Epoch 24/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1041.7250 - val_loss: 11185.8262\n",
      "Epoch 25/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 998.6752 - val_loss: 11045.6289\n",
      "Epoch 26/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1118.4337 - val_loss: 8517.7334\n",
      "Epoch 27/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1042.0842 - val_loss: 8798.4922\n",
      "Epoch 28/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 939.5226 - val_loss: 9488.1943\n",
      "Epoch 29/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 856.5855 - val_loss: 8468.6084\n",
      "Epoch 30/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 950.8416 - val_loss: 8723.3857\n",
      "Epoch 31/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 850.5124 - val_loss: 10062.9424\n",
      "Epoch 32/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 776.8047 - val_loss: 8615.7217\n",
      "Epoch 33/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 842.5840 - val_loss: 8233.3955\n",
      "Epoch 34/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 786.6618 - val_loss: 7951.8569\n",
      "Epoch 35/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 840.8666 - val_loss: 8260.4775\n",
      "Epoch 36/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 771.5289 - val_loss: 6869.5415\n",
      "Epoch 37/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 760.3175 - val_loss: 7664.5889\n",
      "Epoch 38/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 921.7525 - val_loss: 7369.0469\n",
      "Epoch 39/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 829.1663 - val_loss: 8153.7397\n",
      "Epoch 40/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 916.6690 - val_loss: 7208.8989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
      "\n",
      " Training Modell mit Seed 3\n",
      "Epoch 1/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - loss: 70599.3281 - val_loss: 100273.8516\n",
      "Epoch 2/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 22431.2637 - val_loss: 10361.2041\n",
      "Epoch 3/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 6024.3618 - val_loss: 5793.5176\n",
      "Epoch 4/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 3418.1533 - val_loss: 6265.6973\n",
      "Epoch 5/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 2899.5247 - val_loss: 11448.3701\n",
      "Epoch 6/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 2267.1882 - val_loss: 7618.6323\n",
      "Epoch 7/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1988.7417 - val_loss: 10548.2891\n",
      "Epoch 8/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1896.7198 - val_loss: 10422.6572\n",
      "Epoch 9/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1472.8425 - val_loss: 7626.6987\n",
      "Epoch 10/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 1473.3632 - val_loss: 6243.9385\n",
      "Epoch 11/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1326.9215 - val_loss: 6846.7939\n",
      "Epoch 12/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1416.9901 - val_loss: 8577.4287\n",
      "Epoch 13/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1291.1718 - val_loss: 9193.6250\n",
      "Epoch 14/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1384.9266 - val_loss: 7710.2388\n",
      "Epoch 15/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1373.2026 - val_loss: 8301.8125\n",
      "Epoch 16/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1199.0797 - val_loss: 9647.9482\n",
      "Epoch 17/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1162.2482 - val_loss: 11437.8262\n",
      "Epoch 18/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1344.9305 - val_loss: 12417.2344\n",
      "Epoch 19/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1413.6874 - val_loss: 9337.0742\n",
      "Epoch 20/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1153.4141 - val_loss: 11693.4629\n",
      "Epoch 21/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1107.0994 - val_loss: 9001.5020\n",
      "Epoch 22/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1321.5420 - val_loss: 8535.2217\n",
      "Epoch 23/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 974.0270 - val_loss: 8175.9033\n",
      "Epoch 24/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1005.7581 - val_loss: 9861.8525\n",
      "Epoch 25/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1067.0419 - val_loss: 9572.2881\n",
      "Epoch 26/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1055.2273 - val_loss: 9298.8740\n",
      "Epoch 27/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1181.2268 - val_loss: 8586.9043\n",
      "Epoch 28/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1167.9952 - val_loss: 9681.9150\n",
      "Epoch 29/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 1153.5310 - val_loss: 11065.8447\n",
      "Epoch 30/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1007.6224 - val_loss: 13215.6895\n",
      "Epoch 31/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1021.5005 - val_loss: 12722.9365\n",
      "Epoch 32/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 946.1877 - val_loss: 11735.3369\n",
      "Epoch 33/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1116.4635 - val_loss: 12671.0410\n",
      "Epoch 34/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1001.3770 - val_loss: 10607.6475\n",
      "Epoch 35/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1043.8677 - val_loss: 7718.9551\n",
      "Epoch 36/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 941.1909 - val_loss: 10610.0088\n",
      "Epoch 37/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 964.2142 - val_loss: 11554.3320\n",
      "Epoch 38/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 771.4726 - val_loss: 10725.5186\n",
      "Epoch 39/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 693.1252 - val_loss: 10297.2295\n",
      "Epoch 40/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 844.7167 - val_loss: 9324.5410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "\n",
      " Training Modell mit Seed 4\n",
      "Epoch 1/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 70350.1016 - val_loss: 22402.6816\n",
      "Epoch 2/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 19495.8047 - val_loss: 32121.2910\n",
      "Epoch 3/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 5533.7344 - val_loss: 13644.8662\n",
      "Epoch 4/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 3634.2925 - val_loss: 7174.5605\n",
      "Epoch 5/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 2800.0076 - val_loss: 13241.5664\n",
      "Epoch 6/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 2755.9531 - val_loss: 15754.1123\n",
      "Epoch 7/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 2174.8679 - val_loss: 15021.5742\n",
      "Epoch 8/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1951.0586 - val_loss: 16939.1133\n",
      "Epoch 9/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 2029.1356 - val_loss: 17877.0391\n",
      "Epoch 10/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1580.2040 - val_loss: 15247.5791\n",
      "Epoch 11/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1695.9618 - val_loss: 14214.3584\n",
      "Epoch 12/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1776.6980 - val_loss: 14374.3438\n",
      "Epoch 13/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1411.3075 - val_loss: 11807.7246\n",
      "Epoch 14/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1490.0989 - val_loss: 14596.5830\n",
      "Epoch 15/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1419.1168 - val_loss: 11734.9102\n",
      "Epoch 16/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1478.6768 - val_loss: 8087.8257\n",
      "Epoch 17/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1286.7413 - val_loss: 8047.4287\n",
      "Epoch 18/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1280.8351 - val_loss: 11623.0889\n",
      "Epoch 19/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1286.1259 - val_loss: 12926.6582\n",
      "Epoch 20/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1171.2308 - val_loss: 10903.3291\n",
      "Epoch 21/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 962.7856 - val_loss: 10454.5791\n",
      "Epoch 22/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1161.0345 - val_loss: 7788.0215\n",
      "Epoch 23/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1226.3781 - val_loss: 10056.0205\n",
      "Epoch 24/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1113.8588 - val_loss: 11212.9746\n",
      "Epoch 25/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1182.9475 - val_loss: 8081.1230\n",
      "Epoch 26/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1014.9422 - val_loss: 10867.4941\n",
      "Epoch 27/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1056.6124 - val_loss: 9563.6309\n",
      "Epoch 28/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1042.7703 - val_loss: 8122.2646\n",
      "Epoch 29/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1136.9727 - val_loss: 7667.5283\n",
      "Epoch 30/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 970.8773 - val_loss: 10210.7480\n",
      "Epoch 31/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 881.0644 - val_loss: 8642.5635\n",
      "Epoch 32/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 900.8758 - val_loss: 9977.8662\n",
      "Epoch 33/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1149.2053 - val_loss: 7706.7549\n",
      "Epoch 34/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 1009.5427 - val_loss: 6194.6587\n",
      "Epoch 35/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 850.8831 - val_loss: 7126.5073\n",
      "Epoch 36/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 972.6539 - val_loss: 9317.9961\n",
      "Epoch 37/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 963.6591 - val_loss: 9871.8008\n",
      "Epoch 38/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 840.4178 - val_loss: 7101.4956\n",
      "Epoch 39/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 924.2352 - val_loss: 8367.3213\n",
      "Epoch 40/400\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 770.2948 - val_loss: 7825.4087\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000029A74C03880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "Fertig! Datei gespeichert: predictions_NN_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "#optimization of the code above\n",
    "#add dropout, cosine LR Decay, layer setup, early stopping, 5 times ensemble\n",
    "\n",
    "#massive overfitting !!!!!\n",
    "# -----------------------\n",
    "# 1) Dataset (wie bei dir)\n",
    "# -----------------------\n",
    "batch_size = 128\n",
    "\n",
    "# Validation Split (15%)\n",
    "val_split = int(len(X_train) * 0.15)\n",
    "X_val = X_train[:val_split]\n",
    "y_val = y_train[:val_split]\n",
    "X_tr = X_train[val_split:]\n",
    "y_tr = y_train[val_split:]\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_tr, y_tr.astype(\"float32\")))\n",
    "ds_train = ds_train.shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((X_val, y_val.astype(\"float32\")))\n",
    "ds_val = ds_val.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2) Cosine LR Decay\n",
    "# -----------------------\n",
    "def get_optimizer():\n",
    "    lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "        initial_learning_rate=1e-3,\n",
    "        first_decay_steps=2500,\n",
    "        t_mul=1.5,\n",
    "        m_mul=0.9,\n",
    "        alpha=1e-4,\n",
    "    )\n",
    "    return tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3) Modell-Builder\n",
    "# -----------------------\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(num_features,)),\n",
    "\n",
    "        tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.15),\n",
    "\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=get_optimizer(),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4) Training Settings\n",
    "# -----------------------\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=40,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 5) Ensemble (5 Modelle)\n",
    "# -----------------------\n",
    "all_preds = []\n",
    "\n",
    "for seed in [0, 1, 2, 3, 4]:\n",
    "    print(f\"\\n Training Modell mit Seed {seed}\")\n",
    "\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=400,\n",
    "        verbose=1,\n",
    "        callbacks=[callback]\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_test, batch_size=1024).flatten()\n",
    "    all_preds.append(preds)\n",
    "\n",
    "# Mittelwert der Predictions\n",
    "final_pred = np.mean(all_preds, axis=0)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 6) CSV Export\n",
    "# -----------------------\n",
    "sub = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"Tm\": final_pred\n",
    "})\n",
    "\n",
    "sub.to_csv(\"Submissions/predictions_NN_ensemble.csv\", index=False)\n",
    "\n",
    "print(\"Fertig! Datei gespeichert: predictions_NN_ensemble.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f81ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 56770.7344 - val_loss: 13470.7559\n",
      "Epoch 2/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13629.0557 - val_loss: 10779.4102\n",
      "Epoch 3/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11437.8926 - val_loss: 7755.0591\n",
      "Epoch 4/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9680.0117 - val_loss: 6979.7056\n",
      "Epoch 5/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9551.7695 - val_loss: 6661.0327\n",
      "Epoch 6/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8644.5166 - val_loss: 6273.1128\n",
      "Epoch 7/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8282.9805 - val_loss: 6319.1064\n",
      "Epoch 8/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7675.9805 - val_loss: 5824.4336\n",
      "Epoch 9/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6950.4189 - val_loss: 4927.8667\n",
      "Epoch 10/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6867.1104 - val_loss: 4695.7075\n",
      "Epoch 11/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6009.8379 - val_loss: 4622.7075\n",
      "Epoch 12/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5603.2158 - val_loss: 4151.5098\n",
      "Epoch 13/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5053.7783 - val_loss: 3943.5435\n",
      "Epoch 14/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4531.8867 - val_loss: 3776.0571\n",
      "Epoch 15/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4419.5273 - val_loss: 5236.8657\n",
      "Epoch 16/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4502.1689 - val_loss: 3807.9041\n",
      "Epoch 17/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4294.1309 - val_loss: 3713.1572\n",
      "Epoch 18/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4121.5986 - val_loss: 3908.5229\n",
      "Epoch 19/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3637.2800 - val_loss: 4090.7485\n",
      "Epoch 20/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3784.1802 - val_loss: 3571.2070\n",
      "Epoch 21/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3518.9109 - val_loss: 3712.2781\n",
      "Epoch 22/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3527.4412 - val_loss: 3635.7219\n",
      "Epoch 23/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3896.2668 - val_loss: 5000.2402\n",
      "Epoch 24/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3496.7842 - val_loss: 3703.9443\n",
      "Epoch 25/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3213.7546 - val_loss: 3387.9888\n",
      "Epoch 26/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3122.1477 - val_loss: 3286.4788\n",
      "Epoch 27/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3096.1575 - val_loss: 3305.4202\n",
      "Epoch 28/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2966.3245 - val_loss: 3179.2942\n",
      "Epoch 29/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2954.6116 - val_loss: 3205.3276\n",
      "Epoch 30/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2790.0728 - val_loss: 3205.9912\n",
      "Epoch 31/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2733.0393 - val_loss: 3726.5408\n",
      "Epoch 32/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2740.2585 - val_loss: 3681.0586\n",
      "Epoch 33/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2740.7256 - val_loss: 3584.5325\n",
      "Epoch 34/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2808.0237 - val_loss: 3256.4954\n",
      "Epoch 35/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2654.6174 - val_loss: 3740.3123\n",
      "Epoch 36/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2568.3633 - val_loss: 3160.1958\n",
      "Epoch 37/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2607.6523 - val_loss: 4026.4670\n",
      "Epoch 38/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2720.3555 - val_loss: 3866.7354\n",
      "Epoch 39/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2482.9529 - val_loss: 4168.8833\n",
      "Epoch 40/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2695.3481 - val_loss: 3364.1694\n",
      "Epoch 41/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2381.0833 - val_loss: 3172.2180\n",
      "Epoch 42/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2491.3628 - val_loss: 3166.5063\n",
      "Epoch 43/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2189.9839 - val_loss: 3886.4834\n",
      "Epoch 44/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2364.3259 - val_loss: 3646.8342\n",
      "Epoch 45/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2241.0732 - val_loss: 3135.6736\n",
      "Epoch 46/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2172.9939 - val_loss: 3199.9985\n",
      "Epoch 47/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2206.8931 - val_loss: 3198.4609\n",
      "Epoch 48/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2235.8098 - val_loss: 3499.6968\n",
      "Epoch 49/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2428.1995 - val_loss: 4068.6636\n",
      "Epoch 50/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2265.6570 - val_loss: 3503.3948\n",
      "Epoch 51/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2145.9375 - val_loss: 3696.7139\n",
      "Epoch 52/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1965.9703 - val_loss: 3346.7710\n",
      "Epoch 53/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2119.9417 - val_loss: 3372.5442\n",
      "Epoch 54/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2014.1176 - val_loss: 3425.3708\n",
      "Epoch 55/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2069.6128 - val_loss: 3238.9709\n",
      "Epoch 56/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2044.3199 - val_loss: 3233.4448\n",
      "Epoch 57/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2052.6201 - val_loss: 3423.8020\n",
      "Epoch 58/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1968.4910 - val_loss: 3460.3938\n",
      "Epoch 59/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2019.3699 - val_loss: 3265.2979\n",
      "Epoch 60/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2021.5758 - val_loss: 3465.8887\n",
      "Epoch 61/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1931.2466 - val_loss: 3343.9338\n",
      "Epoch 62/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2020.1494 - val_loss: 4054.7922\n",
      "Epoch 63/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1936.5137 - val_loss: 3327.6096\n",
      "Epoch 64/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1823.7738 - val_loss: 3391.8884\n",
      "Epoch 65/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1769.4730 - val_loss: 3507.5435\n",
      "Epoch 66/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2056.0891 - val_loss: 3124.9106\n",
      "Epoch 67/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2153.8276 - val_loss: 3243.6292\n",
      "Epoch 68/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1855.9934 - val_loss: 3253.1228\n",
      "Epoch 69/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1778.1484 - val_loss: 3596.9185\n",
      "Epoch 70/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1810.2285 - val_loss: 3514.9863\n",
      "Epoch 71/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1864.2769 - val_loss: 3307.0623\n",
      "Epoch 72/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1734.5220 - val_loss: 3217.9888\n",
      "Epoch 73/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1841.1127 - val_loss: 3400.9324\n",
      "Epoch 74/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1729.7421 - val_loss: 4025.6370\n",
      "Epoch 75/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1609.1587 - val_loss: 3548.0630\n",
      "Epoch 76/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1776.8757 - val_loss: 3460.8894\n",
      "Epoch 77/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1779.4312 - val_loss: 3422.7463\n",
      "Epoch 78/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1727.5602 - val_loss: 3778.1370\n",
      "Epoch 79/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1878.1154 - val_loss: 3365.8162\n",
      "Epoch 80/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1789.0890 - val_loss: 3776.5640\n",
      "Epoch 81/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1625.2834 - val_loss: 3735.2976\n",
      "Epoch 82/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1685.8425 - val_loss: 3938.7681\n",
      "Epoch 83/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1699.0582 - val_loss: 3479.2939\n",
      "Epoch 84/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1747.6757 - val_loss: 3222.8840\n",
      "Epoch 85/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1764.7131 - val_loss: 3985.7844\n",
      "Epoch 86/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1667.2262 - val_loss: 3363.4058\n",
      "Epoch 87/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1746.5284 - val_loss: 3466.2869\n",
      "Epoch 88/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1566.7443 - val_loss: 3550.3816\n",
      "Epoch 89/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1639.7765 - val_loss: 3293.1445\n",
      "Epoch 90/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1621.9985 - val_loss: 4416.6938\n",
      "Epoch 91/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1493.6815 - val_loss: 3387.8882\n",
      "Epoch 92/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1636.2629 - val_loss: 3891.3643\n",
      "Epoch 93/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1552.6968 - val_loss: 3661.1240\n",
      "Epoch 94/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1615.7876 - val_loss: 3680.4058\n",
      "Epoch 95/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1521.9987 - val_loss: 3408.7087\n",
      "Epoch 96/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1523.6073 - val_loss: 4423.8149\n",
      "Epoch 97/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1672.6124 - val_loss: 3282.7402\n",
      "Epoch 98/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1665.5688 - val_loss: 3862.3840\n",
      "Epoch 99/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1680.3380 - val_loss: 3800.5098\n",
      "Epoch 100/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1456.4939 - val_loss: 3400.9688\n",
      "Epoch 101/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1526.0457 - val_loss: 3877.8171\n",
      "Epoch 102/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1524.2889 - val_loss: 3902.1318\n",
      "Epoch 103/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1357.0488 - val_loss: 3542.8152\n",
      "Epoch 104/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1522.7689 - val_loss: 3992.0435\n",
      "Epoch 105/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1546.5021 - val_loss: 3617.7998\n",
      "Epoch 106/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1367.3336 - val_loss: 3312.7153\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000029A6D1B7240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "#not as good as the second approach\n",
    "batch_size = 128\n",
    "val_split = int(len(X_train) * 0.15)\n",
    "\n",
    "X_val = X_train[:val_split]\n",
    "y_val = y_train[:val_split]\n",
    "X_tr = X_train[val_split:]\n",
    "y_tr = y_train[val_split:]\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_tr, y_tr.astype(\"float32\")))\n",
    "ds_train = ds_train.shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((X_val, y_val.astype(\"float32\")))\n",
    "ds_val = ds_val.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Anti-Overfitting Model\n",
    "# -------------------\n",
    "def build_model():\n",
    "    reg = tf.keras.regularizers.l2(1e-5)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input((X_train.shape[1],)),\n",
    "\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dropout(0.30),\n",
    "\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dropout(0.20),\n",
    "\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=reg),\n",
    "\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Training\n",
    "# -------------------\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=40,\n",
    "    restore_best_weights=True,\n",
    "    monitor=\"val_loss\"\n",
    ")\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=300,\n",
    "    validation_data=ds_val,\n",
    "    callbacks=[callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# Predict\n",
    "# -------------------\n",
    "pred = model.predict(X_test).flatten()\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"Tm\": pred\n",
    "}).to_csv(\"Submissions/predictions_NN_regularized.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f1e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Trial:\n",
      "{'n_hidden_1': 890, 'n_hidden_2': 382, 'n_hidden_3': 29, 'learning_rate': 0.0006289872944239899, 'dropout': 0.09346698381557328, 'batch_size': 128, 'activation': 'gelu'}\n",
      "Epoch 1/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 42332.8750\n",
      "Epoch 2/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 11948.4014\n",
      "Epoch 3/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7789.4575\n",
      "Epoch 4/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6436.6538\n",
      "Epoch 5/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5085.0171\n",
      "Epoch 6/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4344.1338\n",
      "Epoch 7/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 3646.9148\n",
      "Epoch 8/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 3171.9226\n",
      "Epoch 9/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2863.3147\n",
      "Epoch 10/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2595.1758\n",
      "Epoch 11/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2461.6191\n",
      "Epoch 12/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2226.8899\n",
      "Epoch 13/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2067.4333\n",
      "Epoch 14/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1965.9041\n",
      "Epoch 15/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1809.3002\n",
      "Epoch 16/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1715.1371\n",
      "Epoch 17/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1635.4829\n",
      "Epoch 18/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1437.5250\n",
      "Epoch 19/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1416.0265\n",
      "Epoch 20/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1284.9293\n",
      "Epoch 21/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1288.0088\n",
      "Epoch 22/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1113.7484\n",
      "Epoch 23/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1137.4623\n",
      "Epoch 24/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1115.0511\n",
      "Epoch 25/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1066.3318\n",
      "Epoch 26/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 995.4229 \n",
      "Epoch 27/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 971.6836\n",
      "Epoch 28/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 839.7316\n",
      "Epoch 29/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 785.8185\n",
      "Epoch 30/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 789.5347\n",
      "Epoch 31/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 717.8268\n",
      "Epoch 32/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 722.1908\n",
      "Epoch 33/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 758.7858\n",
      "Epoch 34/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 664.3448\n",
      "Epoch 35/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 766.0651\n",
      "Epoch 36/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 683.2365\n",
      "Epoch 37/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 601.8179\n",
      "Epoch 38/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 561.3316\n",
      "Epoch 39/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 539.5480\n",
      "Epoch 40/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 490.4635\n",
      "Epoch 41/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 548.6161\n",
      "Epoch 42/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 491.2202\n",
      "Epoch 43/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 503.3873\n",
      "Epoch 44/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 457.3580\n",
      "Epoch 45/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 446.7151\n",
      "Epoch 46/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 505.5206\n",
      "Epoch 47/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 463.0179\n",
      "Epoch 48/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 403.9736\n",
      "Epoch 49/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 390.9917\n",
      "Epoch 50/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 376.7835\n",
      "Epoch 51/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 373.0750\n",
      "Epoch 52/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 367.9055\n",
      "Epoch 53/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 389.5178\n",
      "Epoch 54/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 440.4353\n",
      "Epoch 55/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 500.4862\n",
      "Epoch 56/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 374.6428\n",
      "Epoch 57/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 409.8744\n",
      "Epoch 58/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 421.7228\n",
      "Epoch 59/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 337.7455\n",
      "Epoch 60/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 378.5328\n",
      "Epoch 61/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 392.3179\n",
      "Epoch 62/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 360.3289\n",
      "Epoch 63/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 375.1048\n",
      "Epoch 64/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 343.7694\n",
      "Epoch 65/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 286.0038\n",
      "Epoch 66/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 260.6707\n",
      "Epoch 67/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 286.2211\n",
      "Epoch 68/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 250.9786\n",
      "Epoch 69/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 294.6607\n",
      "Epoch 70/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 294.0623\n",
      "Epoch 71/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 278.6660\n",
      "Epoch 72/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 283.0287\n",
      "Epoch 73/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 252.3248\n",
      "Epoch 74/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 269.5880\n",
      "Epoch 75/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 266.3708\n",
      "Epoch 76/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 256.3173\n",
      "Epoch 77/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 245.4341\n",
      "Epoch 78/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 250.6024\n",
      "Epoch 79/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 236.1073\n",
      "Epoch 80/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 245.2510\n",
      "Epoch 81/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 209.8927\n",
      "Epoch 82/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 222.5079\n",
      "Epoch 83/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 247.3241\n",
      "Epoch 84/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 270.0367\n",
      "Epoch 85/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 242.1370\n",
      "Epoch 86/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 252.8931\n",
      "Epoch 87/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 299.7588\n",
      "Epoch 88/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 286.3678\n",
      "Epoch 89/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 295.9031\n",
      "Epoch 90/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 221.3814\n",
      "Epoch 91/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 220.8199\n",
      "Epoch 92/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 213.1543\n",
      "Epoch 93/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 212.2764\n",
      "Epoch 94/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 203.9279\n",
      "Epoch 95/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 242.0503\n",
      "Epoch 96/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 210.0464\n",
      "Epoch 97/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 186.6120\n",
      "Epoch 98/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 265.9377\n",
      "Epoch 99/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 190.9005\n",
      "Epoch 100/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 187.2424\n",
      "Epoch 101/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 186.8248\n",
      "Epoch 102/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 246.6291\n",
      "Epoch 103/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 202.4176\n",
      "Epoch 104/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 190.4660\n",
      "Epoch 105/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 188.4589\n",
      "Epoch 106/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 197.8672\n",
      "Epoch 107/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 234.6536\n",
      "Epoch 108/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 201.8450\n",
      "Epoch 109/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 196.1582\n",
      "Epoch 110/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 222.8905\n",
      "Epoch 111/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 252.0817\n",
      "Epoch 112/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 281.1091\n",
      "Epoch 113/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 256.4441\n",
      "Epoch 114/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 202.8911\n",
      "Epoch 115/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 203.2434\n",
      "Epoch 116/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 201.8936\n",
      "Epoch 117/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 222.6376\n",
      "Epoch 118/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 174.2639\n",
      "Epoch 119/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 191.2133\n",
      "Epoch 120/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 202.0224\n",
      "Epoch 121/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 198.0190\n",
      "Epoch 122/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 259.2126\n",
      "Epoch 123/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 215.7758\n",
      "Epoch 124/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 201.6110\n",
      "Epoch 125/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 190.0644\n",
      "Epoch 126/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 168.1518\n",
      "Epoch 127/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 176.1900\n",
      "Epoch 128/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 210.1256\n",
      "Epoch 129/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 169.2634\n",
      "Epoch 130/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 169.8414\n",
      "Epoch 131/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 188.6814\n",
      "Epoch 132/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 167.8075\n",
      "Epoch 133/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 159.4785\n",
      "Epoch 134/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 188.9724\n",
      "Epoch 135/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 169.2221\n",
      "Epoch 136/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 160.5076\n",
      "Epoch 137/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 176.4492\n",
      "Epoch 138/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 174.2279\n",
      "Epoch 139/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 206.5789\n",
      "Epoch 140/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 186.4199\n",
      "Epoch 141/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 230.1821\n",
      "Epoch 142/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 234.5906\n",
      "Epoch 143/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 172.4779\n",
      "Epoch 144/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 194.2825\n",
      "Epoch 145/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 153.8476\n",
      "Epoch 146/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 168.7330\n",
      "Epoch 147/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 219.7012\n",
      "Epoch 148/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 244.0563\n",
      "Epoch 149/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 184.0893\n",
      "Epoch 150/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 170.9124\n",
      "Epoch 151/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 214.6955\n",
      "Epoch 152/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 166.2610\n",
      "Epoch 153/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 166.9604\n",
      "Epoch 154/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 173.5340\n",
      "Epoch 155/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 150.8297\n",
      "Epoch 156/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 154.3055\n",
      "Epoch 157/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 155.4340\n",
      "Epoch 158/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 152.5292\n",
      "Epoch 159/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 184.1606\n",
      "Epoch 160/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 156.0693\n",
      "Epoch 161/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 154.5147\n",
      "Epoch 162/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 174.5245\n",
      "Epoch 163/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 212.2266\n",
      "Epoch 164/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 187.4249\n",
      "Epoch 165/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 217.5544\n",
      "Epoch 166/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 171.1157\n",
      "Epoch 167/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 174.3088\n",
      "Epoch 168/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 168.0139\n",
      "Epoch 169/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 155.9798\n",
      "Epoch 170/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 146.9745\n",
      "Epoch 171/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 169.0007\n",
      "Epoch 172/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 145.1169\n",
      "Epoch 173/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 138.2107\n",
      "Epoch 174/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 175.6816\n",
      "Epoch 175/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 144.3576\n",
      "Epoch 176/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 141.1296\n",
      "Epoch 177/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 155.8035\n",
      "Epoch 178/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 146.0592\n",
      "Epoch 179/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 148.9602\n",
      "Epoch 180/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 128.4830\n",
      "Epoch 181/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 143.3445\n",
      "Epoch 182/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 160.6418\n",
      "Epoch 183/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 216.7781\n",
      "Epoch 184/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 209.6716\n",
      "Epoch 185/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 150.1976\n",
      "Epoch 186/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 142.3319\n",
      "Epoch 187/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 184.4727\n",
      "Epoch 188/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 153.1125\n",
      "Epoch 189/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 170.0023\n",
      "Epoch 190/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 132.6082\n",
      "Epoch 191/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 205.5291\n",
      "Epoch 192/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 157.7528\n",
      "Epoch 193/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 149.8105\n",
      "Epoch 194/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 159.1460\n",
      "Epoch 195/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 139.6548\n",
      "Epoch 196/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 167.0984\n",
      "Epoch 197/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 136.6388\n",
      "Epoch 198/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 135.6765\n",
      "Epoch 199/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 139.2494\n",
      "Epoch 200/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 138.6461\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Fertig! predictions_NN_optuna.csv gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# usage of optuna\n",
    "#is worse than the second try\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Daten vorbereiten\n",
    "# ----------------------------------------------------------\n",
    "X_train_np = X_train.astype(\"float32\")\n",
    "y_train_np = y_train.astype(\"float32\")\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_np, y_train_np, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# TF Datasets Funktion\n",
    "def make_dataset(X, y, batch_size):\n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices((X, y))\n",
    "        .shuffle(len(X))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Optuna Objective\n",
    "# ----------------------------------------------------------\n",
    "def objective(trial):\n",
    "\n",
    "    # Hyperparameter suchen\n",
    "    n1 = trial.suggest_int(\"n_hidden_1\", 128, 1024)\n",
    "    n2 = trial.suggest_int(\"n_hidden_2\", 64, 512)\n",
    "    n3 = trial.suggest_int(\"n_hidden_3\", 0, 256)   # 0 = kein Layer 3\n",
    "\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 5e-3, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"selu\", \"gelu\"])\n",
    "\n",
    "    # Dataset\n",
    "    ds_train = make_dataset(X_tr, y_tr, batch_size)\n",
    "    ds_val = make_dataset(X_val, y_val, batch_size)\n",
    "\n",
    "    # --------------------------\n",
    "    # Modell bauen\n",
    "    # --------------------------\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_tr.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(n1, activation=activation))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(n2, activation=activation))\n",
    "\n",
    "    if n3 > 0:\n",
    "        model.add(tf.keras.layers.Dense(n3, activation=activation))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # Training (kurz fr Optuna)\n",
    "    # --------------------------\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=40,        # kurz halten, wird oft ausgefhrt\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Ziel: Minimale Validierungs-MSE\n",
    "    val_loss = min(history.history[\"val_loss\"])\n",
    "    return val_loss\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Optuna ausfhren\n",
    "# ----------------------------------------------------------\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=40)   # 4080 empfohlen\n",
    "\n",
    "print(\"\\nBest Trial:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# FINAL MODEL MIT BESTEN PARAMETERN\n",
    "# ----------------------------------------------------------\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "n1 = best_params[\"n_hidden_1\"]\n",
    "n2 = best_params[\"n_hidden_2\"]\n",
    "n3 = best_params[\"n_hidden_3\"]\n",
    "lr = best_params[\"learning_rate\"]\n",
    "dropout = best_params[\"dropout\"]\n",
    "batch_size = best_params[\"batch_size\"]\n",
    "activation = best_params[\"activation\"]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(X_train_np.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(n1, activation=activation))\n",
    "model.add(tf.keras.layers.Dropout(dropout))\n",
    "model.add(tf.keras.layers.Dense(n2, activation=activation))\n",
    "if n3 > 0:\n",
    "    model.add(tf.keras.layers.Dense(n3, activation=activation))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=\"mse\"\n",
    ")\n",
    "\n",
    "ds_full = make_dataset(X_train_np, y_train_np, batch_size)\n",
    "\n",
    "# ------------- FULL TRAINING ---------------\n",
    "history = model.fit(\n",
    "    ds_full,\n",
    "    epochs=200,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Vorhersagen fr Testdaten\n",
    "# ----------------------------------------------------------\n",
    "pred_test = model.predict(X_test.astype(\"float32\")).flatten()\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"Tm\": pred_test\n",
    "}).to_csv(\"Submissions/predictions_NN_optuna.csv\", index=False)\n",
    "\n",
    "print(\"Fertig! predictions_NN_optuna.csv gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08467232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
